---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: localai
  namespace: localai
spec:
  chart:
    spec:
      chart: local-ai
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: go-skynet
  interval: 1m0s
  values:
    models:
      list:
        - url: "https://huggingface.co/unsloth/llama-3-8b-bnb-4bit/raw/main/model.safetensors"
    #     - url: "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/blob/main/Meta-Llama-3-8B-Instruct-IQ3_M.gguf"
    deployment:
      runtimeClassName: nvidia
    service:
      type: LoadBalancer
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - bigrig
    persistence:
      models:
        storageClass: silverstick
        size: 20Gi
      output:
        storageClass: silverstick