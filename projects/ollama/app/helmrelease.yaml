---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ollama
  namespace: ollama
spec:
  chart:
    spec:
      chart: ollama
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: ollama
  interval: 1m0s
  values:
    # image: 
    #   tag: latest
    ollama:
      gpu:
        enabled: true
        type: nvidia
      models:
        - tinyllama
      insecure: true
    runtimeClassName: nvidia
    service:
      type: LoadBalancer
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - bigrig
    persistentVolume:
      enabled: true
      # storageClass: microk8s-hostpath
    extraEnv:
      - name: OLLAMA_KEEP_ALIVE
        value: "-1"
      - name: CUDA_VISIBLE_DEVICES
        value: "all"
      - name: NVIDIA_VISIBLE_DEVICES
        value: "all"
      - name: NVIDIA_DRIVER_CAPABILITIES
        value: "all"
      - name: OLLAMA_MAX_LOADED_MODELS
        value: "1"