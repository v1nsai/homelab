---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: localai
  namespace: localai
spec:
  chart:
    spec:
      chart: local-ai
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: go-skynet
  interval: 1m0s
  values:
    # models:
    #   list:
    #     - url: "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/blob/main/model.safetensors"
    #       name: tinyllama-1.0
    deployment:
      image:
        tag: latest-gpu-nvidia-cuda-11 # master-cublas-cuda11-ffmpeg # master-cublas-cuda11
      runtimeClassName: nvidia
    service:
      type: LoadBalancer
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - bigrig
    persistence:
      models:
        storageClass: local-path
        size: 100Gi
      output:
        storageClass: local-path